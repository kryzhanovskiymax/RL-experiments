{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c970cad0-1ed2-4c79-b7bb-46f88396978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from environment import TicTacToeEnv\n",
    "from agent import QAgent, RandomAgent, HumanAgent, FixedStrategyAgent\n",
    "from train import DQNTrainer, game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cb8bb-6490-41a5-becd-9ad4608ea20c",
   "metadata": {},
   "source": [
    "# Training agents against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58d6016f-503b-42dc-9c81-82d7827452b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEnv()\n",
    "agent1 = QAgent(env=env,\n",
    "                name='Agent1',\n",
    "                epsilon_decay=0.999,\n",
    "                update_rate=50,\n",
    "                batch_size=32)\n",
    "agent2 = QAgent(env=env,\n",
    "                name='Agent2',\n",
    "                epsilon_decay=0.999,\n",
    "                update_rate=50,\n",
    "                batch_size=128)\n",
    "trainer = DQNTrainer(env=env,\n",
    "                     agent1=agent1,\n",
    "                     agent2=agent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dda0372-db42-4e9e-91b8-1bba0c2d75e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60000/60000 [00:14<00:00, 4242.82it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(episodes=60000, logging=False, board_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ff0dc8cd-3deb-4fb1-9866-a94ab803f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 5 games:\n",
      "Agent1 wins: 5 (1.00)\n",
      "Agent2 wins: 0 (0.00)\n",
      "Draws: 0 (0.00)\n"
     ]
    }
   ],
   "source": [
    "trainer.eval(n_games=5, render_final_board=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1b42b-35fe-474a-bdaa-31927017e5bc",
   "metadata": {},
   "source": [
    "# Train against random policy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08460281-465d-4f19-9b83-cecb85b393e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEnv()\n",
    "agent3 = QAgent(env,\n",
    "                epsilon_decay=0.999,\n",
    "                name='Agent3',\n",
    "                update_rate=50,\n",
    "                batch_size=128)\n",
    "random_policy_agent = RandomAgent(env=env)\n",
    "trainer = DQNTrainer(env=env,\n",
    "                     agent1=agent3,\n",
    "                     agent2=random_policy_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7189b3eb-c4eb-481b-985a-1fc61468a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 800000/800000 [02:31<00:00, 5277.71it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(episodes=800000, log_step=10000, logging=False, board_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d94baa8-dfb1-4b88-961f-f64a5ec55118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 100 games:\n",
      "Agent3 wins: 42 (0.42)\n",
      "RandomAgent wins: 40 (0.40)\n",
      "Draws: 18 (0.18)\n"
     ]
    }
   ],
   "source": [
    "trainer.eval(n_games=100, render_final_board=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e8f03-8b46-4c5d-b717-05c852a38941",
   "metadata": {},
   "source": [
    "# Against fixed policy agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
