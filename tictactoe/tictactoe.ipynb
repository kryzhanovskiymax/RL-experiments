{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c970cad0-1ed2-4c79-b7bb-46f88396978d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from environment import TicTacToeEnv\n",
    "from agent import QAgent, RandomAgent, HumanAgent, FixedStrategyAgent\n",
    "from train import DQNTrainer, game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996cb8bb-6490-41a5-becd-9ad4608ea20c",
   "metadata": {},
   "source": [
    "# Training agents against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d6016f-503b-42dc-9c81-82d7827452b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEnv()\n",
    "agent1 = QAgent(env=env,\n",
    "                name='Agent1',\n",
    "                epsilon_decay=0.999,\n",
    "                update_rate=50,\n",
    "                batch_size=32)\n",
    "agent2 = QAgent(env=env,\n",
    "                name='Agent2',\n",
    "                epsilon=0.8,\n",
    "                gamma=0.9,\n",
    "                update_rate=10)\n",
    "\n",
    "trainer = DQNTrainer(env=env,\n",
    "                     agent1=agent1,\n",
    "                     agent2=agent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dda0372-db42-4e9e-91b8-1bba0c2d75e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|████████████████████████████████████████▉                                                                                                                                                             | 414/2000 [08:09<32:26,  1.23s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train(episodes=2000, logging=False, board_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0dc8cd-3deb-4fb1-9866-a94ab803f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 5 games:\n",
      "Agent1 wins: 0 (0.00)\n",
      "Agent2 wins: 0 (0.00)\n",
      "Draws: 5 (1.00)\n"
     ]
    }
   ],
   "source": [
    "trainer.eval(n_games=5, render_final_board=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e1b42b-35fe-474a-bdaa-31927017e5bc",
   "metadata": {},
   "source": [
    "# Train against random policy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08460281-465d-4f19-9b83-cecb85b393e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToeEnv()\n",
    "agent3 = QAgent(env,\n",
    "                epsilon_decay=0.999,\n",
    "                name='Agent3',\n",
    "                update_rate=50,\n",
    "                batch_size=32)\n",
    "random_policy_agent = RandomAgent(env=env)\n",
    "trainer = DQNTrainer(env=env,\n",
    "                     agent1=agent3,\n",
    "                     agent2=random_policy_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7189b3eb-c4eb-481b-985a-1fc61468a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3000/3000 [02:24<00:00, 20.72it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.train(episodes=10000, logging=False, board_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d94baa8-dfb1-4b88-961f-f64a5ec55118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation over 10 games:\n",
      "Agent3 wins: 4 (0.40)\n",
      "RandomAgent wins: 5 (0.50)\n",
      "Draws: 1 (0.10)\n"
     ]
    }
   ],
   "source": [
    "trainer.eval(n_games=10, render_final_board=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e8f03-8b46-4c5d-b717-05c852a38941",
   "metadata": {},
   "source": [
    "# Against fixed policy agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c136edba-a044-407e-a1ed-c6797130a5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387655d8-fe87-439c-a8da-e348b999a513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278971fc-7100-4c79-bccb-5e68a0053170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
